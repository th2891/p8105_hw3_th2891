Homework 3
================

## Problem 1

Using instacart data

-   exploration of data set

-   number of aisles, most ordered items from aisles

-   plotting items ordered

``` r
library(p8105.datasets)
data("instacart") 
```

``` r
instacart %>% 
  count(aisle, name = "ordered_freq") %>% 
  arrange(desc(ordered_freq)) %>% 
  filter(ordered_freq > 10000) %>% 
  mutate(aisle =
           fct_reorder(aisle, ordered_freq)) %>% 
  ggplot(aes(x = aisle, y = ordered_freq, color = aisle)) +
  geom_point() +
  ylim(10000, 160000)+
  coord_flip()
```

<img src="p8105_hw3_th2891_files/figure-gfm/unnamed-chunk-2-1.png" width="90%" />

There are 1384617 observations in `instacart` and the variables are
order\_id, product\_id, add\_to\_cart\_order, reordered, user\_id,
eval\_set, order\_number, order\_dow, order\_hour\_of\_day,
days\_since\_prior\_order, product\_name, aisle\_id, department\_id,
aisle, department. All variables are class `integer` except for
`eval_set`, `product_name`, `aisle`, and `department` are class
`integer`. The variables named previously are class `character`. There
are 134 aisles represented in `instacart`. Fresh fruits and vegetables
are the most ordered items followed by pacakged vegetables and fruits.

``` r
instacart %>% 
  group_by(aisle, product_name) %>% 
   filter(aisle == "packaged vegetables fruits" | aisle == "dog food care" | aisle == "baking ingredients") %>%
  summarize(n_obs = n()) %>% 
   pivot_wider(
     names_from = product_name, 
     values_from = n_obs
   )
```

    ## `summarise()` has grouped output by 'aisle'. You can override using the `.groups` argument.

    ## # A tibble: 3 × 1,445
    ## # Groups:   aisle [3]
    ##   aisle   `1 to 1 Gluten F… `1-to-1 Baking Fl… `10\\" Graham R… `100% Cacao Nat…
    ##   <chr>               <int>              <int>            <int>            <int>
    ## 1 baking…                11                  7                5                2
    ## 2 dog fo…                NA                 NA               NA               NA
    ## 3 packag…                NA                 NA               NA               NA
    ## # … with 1,440 more variables:
    ## #   100% Cacao Unsweetened Chocolate Baking Bar <int>,
    ## #   100% Natural Stevia Sweetener <int>,
    ## #   100% Natural Sweetener Zero Calorie Packets <int>,
    ## #   100% Natural Zero Calorie Sweetener <int>,
    ## #   100% Organic Einkorn  All-Purpose Flour <int>,
    ## #   100% Organic Premium Whole Wheat Flour <int>, …

Make table showing the mean hour of the day when Pink Lady Apples and
Coffee Ice cream are ordered on each day of the week (2 x 7 table)

``` r
instacart %>% 
  select(product_name, order_hour_of_day, order_dow) %>% 
  filter(product_name == "Coffee Ice Cream" | product_name == "Pink Lady Apples") %>% 
  group_by(product_name, order_dow) %>% 
  summarize(
    mean_hour = mean(order_hour_of_day)
  ) %>% 
  mutate(order_dow = 
    recode(order_dow, 
           "0" = "Monday",
           "1" = "Tuesday",
           "2" = "Wednesday",
           "3" = "Thursday",
           "4" = "Friday",
           "5" = "Saturday",
           "6" = "Sunday")) %>% 
   pivot_wider(
    names_from = order_dow, 
    values_from = mean_hour)
```

    ## `summarise()` has grouped output by 'product_name'. You can override using the `.groups` argument.

    ## # A tibble: 2 × 8
    ## # Groups:   product_name [2]
    ##   product_name     Monday Tuesday Wednesday Thursday Friday Saturday Sunday
    ##   <chr>             <dbl>   <dbl>     <dbl>    <dbl>  <dbl>    <dbl>  <dbl>
    ## 1 Coffee Ice Cream   13.8    14.3      15.4     15.3   15.2     12.3   13.8
    ## 2 Pink Lady Apples   13.4    11.4      11.7     14.2   11.6     12.8   11.9

## Need to do:

-   give illustrative example of observations

-   Make a table showing the three most popular items in each of the
    aisles “baking ingredients”, “dog food care”, and “packaged
    vegetables fruits”. Include the number of times each item is ordered
    in your table.

## Problem 2

Loading brfss data

``` r
library(p8105.datasets)
data("brfss_smart2010") 
```

Data cleaning

-   Overall health, creating ordered responses “poor” to “excellent”

# Need to do

-   how many states observed at 7 or more locations in 2002 and 2010?

``` r
brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health",
         response == "Excellent" | response == "Very good" | response == "Good" | response == "Fair" | response == "Poor") %>% 
  mutate(response = forcats::fct_relevel(response, c("Poor", "Fair", "Good", "Very good", "Excellent"))
  ) %>%
  filter(year == 2002) %>% 
 separate(locationdesc, into = c("state", "county"), convert = TRUE) %>% 
  group_by(state, county) 
```

    ## Warning: Expected 2 pieces. Additional pieces discarded in 785 rows [1, 2, 3, 4,
    ## 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...].

    ## # A tibble: 785 × 24
    ## # Groups:   state, county [155]
    ##     year locationabbr state county    class  topic question response sample_size
    ##    <int> <chr>        <chr> <chr>     <chr>  <chr> <chr>    <fct>          <int>
    ##  1  2002 AL           AL    Jefferson Healt… Over… How is … Excelle…          92
    ##  2  2002 AL           AL    Jefferson Healt… Over… How is … Very go…         142
    ##  3  2002 AL           AL    Jefferson Healt… Over… How is … Good             167
    ##  4  2002 AL           AL    Jefferson Healt… Over… How is … Fair              60
    ##  5  2002 AL           AL    Jefferson Healt… Over… How is … Poor              31
    ##  6  2002 AK           AK    Anchorage Healt… Over… How is … Excelle…         116
    ##  7  2002 AK           AK    Anchorage Healt… Over… How is … Very go…         137
    ##  8  2002 AK           AK    Anchorage Healt… Over… How is … Good             104
    ##  9  2002 AK           AK    Anchorage Healt… Over… How is … Fair              37
    ## 10  2002 AK           AK    Anchorage Healt… Over… How is … Poor              22
    ## # … with 775 more rows, and 15 more variables: data_value <dbl>,
    ## #   confidence_limit_low <dbl>, confidence_limit_high <dbl>,
    ## #   display_order <int>, data_value_unit <chr>, data_value_type <chr>,
    ## #   data_value_footnote_symbol <chr>, data_value_footnote <chr>,
    ## #   data_source <chr>, class_id <chr>, topic_id <chr>, location_id <chr>,
    ## #   question_id <chr>, respid <chr>, geo_location <chr>

## Problem 3

Loading accel data

``` r
accel = 
  read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  rename_with( ~ str_replace(., "activity_", paste0("minute_", seq_along(along.with = NULL)))) %>% 
  mutate(weekend_vs_weekday =
    recode(day, "Saturday" = "Weekend", "Sunday" = "Weekend", "Monday" = "Weekday", "Tuesday" = "Weekday", "Wednesday" = "Weekday", "Thursday" = "Weekday", "Friday" = "Weekday")) %>% 
  select(week, day_id, weekend_vs_weekday, everything()) %>% view
```

    ## Rows: 35 Columns: 1443

    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr    (1): day
    ## dbl (1442): week, day_id, activity.1, activity.2, activity.3, activity.4, ac...

    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

There are 35 observations in `accel`and the variables are week, day\_id,
weekend\_vs\_weekday, and minute\_1 to minute\_1440. All variables are
`numeric` except for `weekend_vs_weekday` and `day` which are class
`character`.
