---
title: "Homework 3"
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "virids"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1 

Using instacart data 

* exploration of data set

* number of aisles, most ordered items from aisles 

* plotting items ordered 



```{r}
library(p8105.datasets)
data("instacart") 

```

Plotting some initial observations


```{r}
instacart %>% 
  count(product_name, name = "count") %>% 
  ggplot(aes(x = product_name, y = count)) + geom_point()
```


```{r}
instacart %>% 
  count(aisle, name = "ordered_freq") %>% 
  arrange(desc(ordered_freq)) %>% 
  filter(ordered_freq > 10000) %>% 
  mutate(aisle =
           fct_reorder(aisle, ordered_freq)) %>% 
  ggplot(aes(x = aisle, y = ordered_freq, color = aisle)) +
  geom_point() +
  ylim(10000, 160000)+
  coord_flip() +
  labs(title = "Orders from grocery aisles", 
       x = "order frequency", 
       y = "aisle name", 
       caption = "Using data from Instacart 2017 dataset to plot the frequency of orders from each aisle")
```


There are `r nrow(instacart)` observations in `instacart` and the variables are `r names(instacart)`. All variables are class `integer` except for `eval_set`, `product_name`, `aisle`, and `department` are class `integer`. The variables named previously are class `character`.
There are 134 aisles represented in `instacart`. Fresh fruits and vegetables are the most ordered items followed by pacakged vegetables and fruits. 

### Making table with 3 most popular items in 3 aisles 

```{r}
pop_products = 
instacart %>% 
  group_by(aisle, product_name) %>% 
   filter(aisle %in% c("packaged vegetables fruits", "dog food care","baking ingredients")) %>%
  summarize(n_obs = n()) %>% 
    arrange(desc(n_obs)) %>% 
   slice(1:3) %>% 
    knitr::kable(digits = 1)
```

Make table showing the mean hour of the day when Pink Lady Apples and Coffee Ice cream are ordered on each day of the week (2 x 7 table)

```{r}
instacart %>% 
  select(product_name, order_hour_of_day, order_dow) %>% 
  filter(product_name == "Coffee Ice Cream" | product_name == "Pink Lady Apples") %>% 
  group_by(product_name, order_dow) %>% 
  summarize(
    mean_hour = mean(order_hour_of_day)
  ) %>% 
  mutate(order_dow = 
    recode(order_dow, 
           "0" = "Monday",
           "1" = "Tuesday",
           "2" = "Wednesday",
           "3" = "Thursday",
           "4" = "Friday",
           "5" = "Saturday",
           "6" = "Sunday")) %>% 
   pivot_wider(
    names_from = order_dow, 
    values_from = mean_hour)
```


## Problem 2

Loading brfss data 

```{r}
library(p8105.datasets)
data("brfss_smart2010") 
```

Data cleaning

* Overall health, creating ordered responses "poor" to "excellent"

# Need to do

* how many states observed at 7 or more locations in 2002 and 2010?

```{r}
brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health",
         response == "Excellent" | response == "Very good" | response == "Good" | response == "Fair" | response == "Poor") %>% 
  mutate(response = forcats::fct_relevel(response, c("Poor", "Fair", "Good", "Very good", "Excellent"))
  ) %>%
  filter(year == 2002) %>% 
 separate(locationdesc, into = c("state", "county"), convert = TRUE) %>% 
  group_by(state) %>% 
  count(state, name = "n_locations") %>% arrange(desc(n_locations)) %>% 
  filter(n_locations > 7)
```
There are 36 states with over 7 locations in 2002. 


2010: 
```{r}
brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health",
         response == "Excellent" | response == "Very good" | response == "Good" | response == "Fair" | response == "Poor") %>% 
  mutate(response = forcats::fct_relevel(response, c("Poor", "Fair", "Good", "Very good", "Excellent"))
  ) %>%
  filter(year == 2010) %>% 
 separate(locationdesc, into = c("state", "county"), convert = TRUE) %>% 
  group_by(state) %>% 
  count(state, name = "n_locations") %>% arrange(desc(n_locations)) %>% 
  filter(n_locations > 7)
```
 There are 45 states with over 7 locations in 2002.


# dataset - response = excellent
```{r}
brfss_df = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(response == "Excellent") %>% 
  group_by(year, locationabbr, data_value)
```


## Problem 3

           
Loading accel data

```{r}
accel_df = read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  rename_with( ~ str_replace(., "activity_", paste0("minute_", seq_along(along.with = NULL)))) %>% 
  mutate(weekend_vs_weekday =
    recode(day, "Saturday" = "Weekend", "Sunday" = "Weekend", "Monday" = "Weekday", "Tuesday" = "Weekday", "Wednesday" = "Weekday", "Thursday" = "Weekday", "Friday" = "Weekday")) %>% 
  select(week, day_id, weekend_vs_weekday, everything()) 
```

There are `r nrow(accel_df)` observations in `accel`and the variables are week, day_id, weekend_vs_weekday, and `minute_1` to `minute_1440`. All variables are `numeric` except for `weekend_vs_weekday` and `day` which are class `character`. 

Aggregate over data for total activity for entire day

* making table for aggregated activity `minute_1:minute_1440`

```{r}
accel_df %>% 
  rowwise() %>% 
  mutate(total_activity = sum(c_across(minute_1:minute_1440), na.rm = TRUE)) %>%
  select(day_id, day, total_activity)
```

* looking for trends in `total_activity`

```{r}
accel_df %>% 
  rowwise() %>% 
  mutate(total_activity = sum(c_across(minute_1:minute_1440), na.rm = TRUE)) %>% 
  mutate(as.integer(total_activity)) %>% 
  select(day_id, day, total_activity) %>% 
  group_by(day) %>% 
  summarize(mean_activity = mean(total_activity))
```


From the `accel` data, looking at `total_activity`, on average, `Friday` has the most activity, followed by `Wednesday` and `Thursday`. On average, `Saturday` has the lowest activity score. 

Making a plot for activity in 24 hour period for each day of the week.

```{r}
accel_df %>% 
  select(day, minute_1:minute_1440) %>% 
  pivot_longer(
    minute_1:minute_1440,
    names_to = "time",
    values_to = "activity") %>% 
   separate(time, into = c("unit", "min_num"), convert = TRUE) %>% mutate(min_num = min_num) %>% 
  mutate(min_num = as.numeric(min_num)) %>% 
  group_by(day, min_num) %>% 
  summarize(avg_activity = mean(activity)) %>% 
  ggplot(aes(x = min_num, y = avg_activity, color = day)) + geom_smooth(se = FALSE) +
  scale_x_discrete(limit = c(360, 720, 1080, 1440),
                   labels = c("6", "12", "18", "24")) +
  labs(
    title = "Average activity over 24 hours, over 7 days",
    x = "time (hrs)",
    y = "Average activity counts",
    color = "day"
  )
```




